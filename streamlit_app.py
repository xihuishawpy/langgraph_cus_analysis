"""Streamlit front-end with LangGraph and CrewAI entry points."""
from __future__ import annotations

import os
import sys
from pathlib import Path
from typing import Any, Dict, List

import streamlit as st
from langchain_core.messages import AIMessage, HumanMessage

PROJECT_ROOT = Path(__file__).resolve().parent
BACKEND_SRC = PROJECT_ROOT / "backend" / "src"
if str(BACKEND_SRC) not in sys.path:
    sys.path.insert(0, str(BACKEND_SRC))

from agent.graph import graph  # noqa: E402
from crewai_app.configuration import Configuration  # noqa: E402
from crewai_app.crew_builder import ProSearchCrewBuilder  # noqa: E402

st.set_page_config(page_title="Pro Search Agent", layout="wide")
st.title("ğŸ” Pro Search Agent")

REQUIRED_KEYS = ["DASHSCOPE_API_KEY", "TAVILY_API_KEY"]
missing_keys = [name for name in REQUIRED_KEYS if not os.getenv(name)]
if missing_keys:
    st.error(
        "ç¼ºå°‘ä»¥ä¸‹ç¯å¢ƒå˜é‡ï¼Œè¯·åœ¨ç»ˆç«¯æˆ– .env ä¸­é…ç½®åå†è¿è¡Œï¼š\n" + ", ".join(missing_keys)
    )
    st.stop()

if "langgraph_runs" not in st.session_state:
    st.session_state["langgraph_runs"] = []
if "crewai_runs" not in st.session_state:
    st.session_state["crewai_runs"] = []


def render_langgraph_results(runs: List[Dict[str, Any]]) -> None:
    for idx, run in enumerate(runs, start=1):
        header = f"è¿è¡Œ {idx}: {run['query'][:40]}" + ("..." if len(run["query"]) > 40 else "")
        with st.expander(header, expanded=(idx == 1)):
            status = run["status"]
            if status == "error":
                st.error(run.get("error", "æœªçŸ¥é”™è¯¯"))
                continue
            if status == "running":
                st.info("ä»»åŠ¡æ‰§è¡Œä¸­...")
                continue
            result = run["result"]
            messages: List[Any] = result.get("messages", [])
            answer = next((msg.content for msg in reversed(messages) if isinstance(msg, AIMessage)), None)
            if answer:
                st.subheader("æœ€ç»ˆå›ç­”")
                st.markdown(answer)
            summaries = result.get("web_research_result", [])
            if summaries:
                st.subheader("é˜¶æ®µæ€§æ‘˜è¦")
                for i, summary in enumerate(summaries, start=1):
                    st.markdown(f"**æ‘˜è¦ {i}:**\n{summary}")
            sources = result.get("sources_gathered", [])
            if sources:
                st.subheader("å¼•ç”¨æ¥æº")
                for source in sources:
                    label = source.get("label") or source.get("short_url")
                    url = source.get("value") or source.get("short_url")
                    st.markdown(f"- [{label}]({url})")
            st.caption("åŸå§‹çŠ¶æ€ " + repr({k: v for k, v in result.items() if k != "messages"}))


def render_crewai_results(runs: List[Dict[str, Any]]) -> None:
    for idx, run in enumerate(runs, start=1):
        header = f"è¿è¡Œ {idx}: {run['query'][:40]}" + ("..." if len(run["query"]) > 40 else "")
        with st.expander(header, expanded=(idx == 1)):
            status = run["status"]
            if status == "error":
                st.error(run.get("error", "æœªçŸ¥é”™è¯¯"))
                continue
            if status == "running":
                st.info("ä»»åŠ¡æ‰§è¡Œä¸­...")
                continue
            st.subheader("CrewAI è¾“å‡º")
            st.markdown(run["result_markdown"])


def run_langgraph_agent(query: str, overrides: Dict[str, Any], reasoning_model: str) -> Dict[str, Any]:
    state: Dict[str, Any] = {"messages": [HumanMessage(content=query)]}
    if reasoning_model.strip():
        state["reasoning_model"] = reasoning_model.strip()
    return graph.invoke(state, config={"configurable": overrides})


def run_crewai_agent(query: str, overrides: Dict[str, Any]) -> str:
    configuration = Configuration.from_runnable_config({"configurable": overrides})
    builder = ProSearchCrewBuilder(configuration, verbose=False)
    crew = builder.build(query)
    result = crew.kickoff(inputs={"topic": query})
    return getattr(result, "raw", str(result))


tab_lang, tab_crewai = st.tabs(["LangGraph å·¥ä½œæµ", "CrewAI å·¥ä½œæµ"])

with tab_lang:
    st.subheader("LangGraph å¤šèŠ‚ç‚¹æ™ºèƒ½ä½“")
    cfg_col, run_col = st.columns([1, 2])
    with cfg_col:
        st.markdown("#### è¿è¡Œé…ç½®")
        initial_queries = st.number_input("åˆå§‹æœç´¢æŸ¥è¯¢æ•°é‡", min_value=1, max_value=6, value=3, key="lg_initial_queries")
        max_loops = st.slider("æœ€å¤§ç ”ç©¶å¾ªç¯æ¬¡æ•°", min_value=1, max_value=5, value=1, key="lg_max_loops")
        use_kb_search = st.checkbox("å¯ç”¨å†…éƒ¨çŸ¥è¯†åº“æ£€ç´¢", value=True, key="lg_use_kb")
        kb_top_k = st.slider(
            "çŸ¥è¯†åº“è¿”å›æ¡æ•°",
            min_value=1,
            max_value=30,
            value=10,
            disabled=not use_kb_search,
            key="lg_kb_topk",
        )
        query_model = st.text_input("æŸ¥è¯¢ç”Ÿæˆæ¨¡å‹", value="qwen-plus", key="lg_query_model")
        reflection_model = st.text_input("åæ€æ¨¡å‹", value="qwen-plus", key="lg_reflection_model")
        answer_model = st.text_input("å›ç­”æ¨¡å‹", value="qwen-plus", key="lg_answer_model")
        reasoning_model = st.text_input("æ¨ç†æ¨¡å‹ (å¯é€‰)", value="", key="lg_reasoning_model")
        embedding_model = st.text_input(
            "çŸ¥è¯†åº“å‘é‡æ¨¡å‹", value="text-embedding-v3", disabled=not use_kb_search, key="lg_embedding_model"
        )
        llm_backend = st.selectbox("LLM åç«¯", options=["dashscope", "local"], index=0, key="lg_llm_backend")
        enable_tongyi_search_summary = st.checkbox(
            "ä½¿ç”¨é€šä¹‰åƒé—®ç”Ÿæˆæœç´¢æ‘˜è¦", value=False, help="é»˜è®¤å…³é—­ï¼Œå¯åœ¨éœ€è¦æ›´è¯¦ç»†ç»¼è¿°æ—¶å¼€å¯", key="lg_tongyi_summary"
        )
    with run_col:
        st.markdown("#### è°ƒç ”è¾“å…¥")
        user_query = st.text_area("ç ”ç©¶é—®é¢˜", height=120, placeholder="ä¾‹å¦‚ï¼šPCB å¢é•¿è¾ƒå¥½çš„ä¼ä¸šåˆ†å¸ƒï¼Ÿ", key="lg_query")
        run_button = st.button("å¼€å§‹ LangGraph è°ƒç ”", type="primary", key="lg_run_button", disabled=not user_query.strip())
    overrides: Dict[str, Any] = {
        "number_of_initial_queries": int(initial_queries),
        "max_research_loops": int(max_loops),
        "knowledge_base_top_k": int(kb_top_k),
        "query_generator_model": query_model.strip() or "qwen-plus",
        "reflection_model": reflection_model.strip() or "qwen-plus",
        "answer_model": answer_model.strip() or "qwen-plus",
        "knowledge_base_paths": os.getenv(
            "KNOWLEDGE_BASE_PATHS",
            "eastmoney_concept_constituents.xlsx,sw_third_industry_constituents.xlsx",
        ),
        "knowledge_base_embedding_model": embedding_model.strip() or "text-embedding-v3",
        "llm_backend": llm_backend,
        "enable_knowledge_base_search": bool(use_kb_search),
        "enable_tongyi_search_summary": bool(enable_tongyi_search_summary),
    }
    if run_button:
        st.session_state["langgraph_runs"].insert(0, {"query": user_query.strip(), "status": "running"})
        try:
            with st.spinner("LangGraph æ™ºèƒ½ä½“æ‰§è¡Œä¸­..."):
                result = run_langgraph_agent(user_query.strip(), overrides, reasoning_model)
        except Exception as exc:  # noqa: BLE001
            st.session_state["langgraph_runs"][0] = {
                "query": user_query.strip(),
                "status": "error",
                "error": str(exc),
            }
        else:
            st.session_state["langgraph_runs"][0] = {
                "query": user_query.strip(),
                "status": "success",
                "result": result,
            }
    st.markdown("---")
    render_langgraph_results(st.session_state["langgraph_runs"])

with tab_crewai:
    st.subheader("CrewAI å¤š Agent å·¥ä½œæµ")
    cfg_col, run_col = st.columns([1, 2])
    with cfg_col:
        st.markdown("#### è¿è¡Œé…ç½®")
        crew_initial_queries = st.number_input("åˆå§‹æœç´¢æŸ¥è¯¢æ•°é‡", min_value=1, max_value=8, value=1, key="crew_initial_queries")
        crew_max_loops = st.slider("æœ€å¤§è¿­ä»£è½®æ•°", min_value=1, max_value=4, value=1, key="crew_max_loops")
        crew_enable_kb = st.checkbox("å¯ç”¨ Excel çŸ¥è¯†åº“", value=True, key="crew_enable_kb")
        crew_kb_top_k = st.slider(
            "çŸ¥è¯†åº“è¿”å›æ¡æ•°",
            min_value=1,
            max_value=20,
            value=5,
            key="crew_kb_topk",
            disabled=not crew_enable_kb,
        )
        crew_disable_industry = st.checkbox("å…³é—­è¡Œä¸šæŠ¥å‘Šæ¨¡æ¿", value=False, key="crew_disable_industry")
        crew_kb_paths = st.text_input(
            "çŸ¥è¯†åº“è·¯å¾„ (é€—å·åˆ†éš”)",
            value=os.getenv(
                "KNOWLEDGE_BASE_PATHS",
                "eastmoney_concept_constituents.xlsx,sw_third_industry_constituents.xlsx",
            ),
            key="crew_kb_paths",
        )
        crew_query_model = st.text_input("æŸ¥è¯¢ç”Ÿæˆæ¨¡å‹", value="qwen-plus", key="crew_query_model")
        crew_reflection_model = st.text_input("åæ€æ¨¡å‹", value="qwen-plus", key="crew_reflection_model")
        crew_answer_model = st.text_input("å›ç­”æ¨¡å‹", value="qwen-plus", key="crew_answer_model")
    with run_col:
        st.markdown("#### è°ƒç ”è¾“å…¥")
        crew_query = st.text_area("ç ”ç©¶é—®é¢˜", height=120, placeholder="ä¾‹å¦‚ï¼šåŠå¯¼ä½“è®¾å¤‡å›½äº§æ›¿ä»£æœ‰å“ªäº›æœºä¼šï¼Ÿ", key="crew_query")
        crew_button = st.button("è¿è¡Œ CrewAI å·¥ä½œæµ", type="primary", key="crew_run_button", disabled=not crew_query.strip())
    crew_overrides = {
        "number_of_initial_queries": int(crew_initial_queries),
        "max_research_loops": int(crew_max_loops),
        "enable_knowledge_base_search": bool(crew_enable_kb),
        "knowledge_base_top_k": int(crew_kb_top_k),
        "knowledge_base_paths": crew_kb_paths.strip(),
        "enable_industry_report_mode": not crew_disable_industry,
        "query_generator_model": crew_query_model.strip() or "qwen-plus",
        "reflection_model": crew_reflection_model.strip() or "qwen-plus",
        "answer_model": crew_answer_model.strip() or "qwen-plus",
    }
    if crew_button:
        st.session_state["crewai_runs"].insert(0, {"query": crew_query.strip(), "status": "running"})
        try:
            with st.spinner("CrewAI æ™ºèƒ½ä½“æ‰§è¡Œä¸­..."):
                output = run_crewai_agent(crew_query.strip(), crew_overrides)
        except Exception as exc:  # noqa: BLE001
            st.session_state["crewai_runs"][0] = {
                "query": crew_query.strip(),
                "status": "error",
                "error": str(exc),
            }
        else:
            st.session_state["crewai_runs"][0] = {
                "query": crew_query.strip(),
                "status": "success",
                "result_markdown": output,
            }
    st.markdown("---")
    render_crewai_results(st.session_state["crewai_runs"])
